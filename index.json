[{"categories":null,"content":"RO-Crate is a method for describing and packaging research data from ANY discipline into distributable, reusable Digital Objects with any amount of detailed metadata from simple who/what/where discovery-oriented description to metadata at the file-level or even variable level inside files. RO-Crate is an implementer-focussed guide to best practice and is based on widely-used standards with schema.org annotations in JSON-LD and aims to make it easy to creat good quality metadata description tools which are accessible and practical for use in a wide variety of situations; from an individual researcher working with a folder of data, to large data-intensive computational research environments. RO-Crate is used in the UTS Research Data Portal and the Modern PARADISEC demonstrator for all data objects. RO-Crate is method for describing a dataset as a digital object using a single linked-data metadata document Each resource can have a machine readable description in JSON-LD format A human-readable description and preview can be in an HTML file that lives alongside the metadata Provenance and workflow information can be included - to assist in data and research-process re-use RO-Crate Digital Objects may be packaged for distribution eg via Zip, Bagit and OCFL Objects ","date":"2024-01-01","objectID":"/standards/ro-crate/:0:0","tags":null,"title":"Metadata: Research Object Crate (RO-Crate)","uri":"/standards/ro-crate/"},{"categories":null,"content":"Oxford Common File Layout (OCFL) is a specification for laying out digital collections on file or object storage. It is designed with long-term preservation principles in mind; does not rely on specialised software and avoids the problem of locking data collections into monolithic repositories behind APIs. An OCFL Repository is a system of directories laid out on a filesystem using a prescribed layout. Each repository contains one or more OCFL Objects. An object contains an inventory and a set of versioned content directories. The metadata describing an OCFL object’s inventory and versions is stored as simple JSON files which are both human- and machine-readable, and can be processed with lightweight scripts. The structure inside the content directories is not specified, so any existing collection of files can be deposited into an OCFL repository and later re-exported with its structure preserved. OCFL places no restrictions on the file formats of object contents. ","date":"2024-01-01","objectID":"/standards/ocfl/:0:0","tags":null,"title":"Standards: Oxford Common File Layout","uri":"/standards/ocfl/"},{"categories":null,"content":"OCFL provides Robustness against file errors and data corruption Efficient versioning and de-duplication Immutable data storage ","date":"2024-01-01","objectID":"/standards/ocfl/:1:0","tags":null,"title":"Standards: Oxford Common File Layout","uri":"/standards/ocfl/"},{"categories":null,"content":"Links OCFL website OCFL Specification v1.0 ","date":"2024-01-01","objectID":"/standards/ocfl/:2:0","tags":null,"title":"Standards: Oxford Common File Layout","uri":"/standards/ocfl/"},{"categories":null,"content":"Example Here is a simplified view of an OCFL repository containing two objects, one of which has two versions and one with three: - OCFL repository - Object A - inventory - v1 - inventory - content - v2 - inventory - content - Object B - v1 - inventory - content - v2 - inventory - content - v3 - inventory - content ","date":"2024-01-01","objectID":"/standards/ocfl/:3:0","tags":null,"title":"Standards: Oxford Common File Layout","uri":"/standards/ocfl/"},{"categories":null,"content":"RRKive is an evolution of of the Arkisto website. This was created at the University of Technology Sydney with a small group of partners, and served to bring together a community of like-minded. The tools mentioned on the Arkisto site were mentioned in the Language Data Commons of Australia proposal and the principles and ideas are still relevant, but we decided to make a new site which which better articulates the principles and is more flexible as to how they may be implemented. While LDaCA has successfully implemented a range of tools that implement the named Arkisto standards, full adoption of the initial standards stack did not suit all partners and the principles were not fully articulated, so with RRKive we aim to clearly separate principles \u0026 requirements from choice of standards, and from implementation in code. ","date":"1970-01-01","objectID":"/background/:0:0","tags":null,"title":"Background","uri":"/background/"},{"categories":null,"content":"Contact Us ","date":"1970-01-01","objectID":"/contact/:0:0","tags":null,"title":"Contact Us","uri":"/contact/"},{"categories":null,"content":"THIS IS A DRAFT / Work in progress that LDaCA staff are preparing for a workshop in early February 2024 – if you have suggestions, or issues - please open issues on our github project The RRKive.org website is an initiative of the Language Data Commons of Australia; one of the partners of the Australian Research Data Commons (ARDC). The initial version of the site (Q1 2024) is intended to be the start of a conversation with our partners and stakeholders, inviting them to critique and refine these principles with a view to collective adoption as part of manifesto, and/or standard architecture for Data Commons. Initially this is technical and word-heavy, but we aim to introduce some graphics to help explain the concepts – once we have brought on board more collaborators and refined these principles. What’s a Data Commons and where’s the data in one? Following the lead of Jenny Fewster, HASS and Indigenous Research Data Commons Director at the Australian Research Data Commons (ARDC) we use this definition for Data Commons (@grossmanCaseDataCommons2016): A global trusted system of systems that provides frictionless access to high quality interoperable resources, services and artefacts for research. The abstract of this article says: Data commons collocate data, storage, and computing infrastructure with core services and commonly used tools and applications for managing, analyzing, and sharing data to create an interoperable resource for the research community. NOTE: This definition differs from others in that it does not use the word “open”, which is important, as not all research data can be made openly available; according to the [FAIR] and [CARE] principles can and should be made accessible to the right people / agents. For some background on FAIR and CARE see this LDaCA blog post. This web site looks at the core services and infrastructure needed to undertake the processes mentioned in the definition: managing, analyzing, and sharing; we do that below, paying particular attention to where the data resides in a Data Commons. This is about Research Data Commons deployments This site is about: A set of principles and an architectural vision for sustainable Data Commons deployments, particularly for data management. A toolkit for deploying granular sustainable archival repository software which can describe and make data accessible down to and inside of the files and datasets but using commodity IT systems to ensure data interoperability Enabling the ‘interoperability’ mentioned in the definition of a Data Commons above. One of the key inspirations for RRKive was the approach taken by PARADISEC (@barwickUnlockingArchives2018) where data is stored and managed using a very simple architecture with data and metadata at its heart sitting, on top of commodity IT services; initially this was a file-system and is now cloud-based object storage. The key idea was that the data should always be available to administrators independently of particular software services (though because some data is not open it is not possible to just put data up on an open webserver – mediation is needed). This site is based on a previous effort know as Arkisto, see the background page. ","date":"1970-01-01","objectID":"/_index_source/:0:0","tags":null,"title":"RRKive Home","uri":"/_index_source/"},{"categories":null,"content":"Scope: what people, domains, institutions, kinds and scales of data is this relevant for? This site is for leaders and implementers of Research Data Commons projects AND general research data management practitioners looking to choose, manage or establish sustainable CARE and FAIR compliant data management solutions that will work with research services. This site is relevant to any research or cultural domain, where teams are establishing data management infrastructure – the initial uses case and implementations are mainly from the Humanities and Social Sciences, with some “sciencey” and generalist deployments. ","date":"1970-01-01","objectID":"/_index_source/:1:0","tags":null,"title":"RRKive Home","uri":"/_index_source/"},{"categories":null,"content":"Not in scope There are a number of data management / Data Commons scenarios where this will be less relevant. Parts of this site are less relevant for domains where very bit of existing and prospective data, and all analytical products and annotations have an identified home with: Persistent Identification Sustainable secure storage for raw and derived data and research outputs at useful granularity – eg down to individually addressable items, files or variables within files Appropriate access control Catalogues / portals to make data discoverable APIs to integrate and interoperate with analytical and data curation processes ","date":"1970-01-01","objectID":"/_index_source/:2:0","tags":null,"title":"RRKive Home","uri":"/_index_source/"},{"categories":null,"content":"Core principles for a sustainable FAIR/CARE data commons architecture: In research contexts, it has been common for investment to be prioritized in research tools for analysis and/or presentation, often at the cost of locking up data in software stacks that make re-use and long-term access difficult, or focus on short term projects with data without ensuring its longevity. Research teams and IT professionals often focus on product – doing novel analyses using data flows and integration without putting in place the services needed for research integrity; assigning IDs and ensuring that those IDs resolve to data over the long term. ","date":"1970-01-01","objectID":"/_index_source/:3:0","tags":null,"title":"RRKive Home","uri":"/_index_source/"},{"categories":null,"content":"Principle 1: Separate Archival Storage FUNCTIONS from Workspaces An overriding principle for the RRKive approach is to Separate concerns between: Workspaces where data is collected, curated, described and analyzed Archival repositories that provide data persistence, persistent ID resolution and appropriate access control ","date":"1970-01-01","objectID":"/_index_source/:3:1","tags":null,"title":"RRKive Home","uri":"/_index_source/"},{"categories":null,"content":"Principle 2: Ensure Archival Repository storage is not locked to a single software stack Keep data in a commodity IT storage system with more than one mode of access Divide up data into chunks (“objects”, “items”) Keep metadata in a standard format adjacent to data files Aim for “rebuildability” of services (eg catalogues \u0026 access control) from the storage system Include a natural-language license with each object setting out how data may be used and/or redistributed and by WHOM ","date":"1970-01-01","objectID":"/_index_source/:3:2","tags":null,"title":"RRKive Home","uri":"/_index_source/"},{"categories":null,"content":"Principle 3: Use an extensible linked-data metadata format Linked Data allows: Any conceivable data structure to be described Vocabularies to be mixed-in as needed; from a core set for all data to domain-specific to project or even dataset-specific terms; this can be formalised using Profiles. Interoperability with global research information systems architectures, discovery services etc While LDaCA is part of the Humanities and Social Sciences and Indigenous Research Data Commons, this vision is by no means limited to that scope – these ideas are relevant to all domains where data is available as file-based objects at a scale that can be managed in file system-like storage.code ","date":"1970-01-01","objectID":"/_index_source/:3:3","tags":null,"title":"RRKive Home","uri":"/_index_source/"},{"categories":null,"content":"References ","date":"1970-01-01","objectID":"/_index_source/:4:0","tags":null,"title":"RRKive Home","uri":"/_index_source/"},{"categories":null,"content":"FAIR \u0026 CARE The FAIR and/or CARE principles are frequently mandated in various contexts around the world, inclduing for outputs of the Australian Research Data Commons (ARDC). not a DIY manual for researchers - to implement a system that supports CARE and FAIR research requires development of infrastructure. They Care Principles - Collective Benefit Data ecosystems shall be designed and function in ways that enable Indigenous Peoples to derive benefit from the data. C1: For inclusive development and innovation Governments and institutions must actively support the use and reuse of data by Indigenous nations and communities by facilitating the establishment of the foundations for Indigenous innovation, value generation, and the promotion of local self-determined development processes. C2: For improved governance and citizen engagement Data enrich the planning, implementation, and evaluation processes that support the service and policy needs of Indigenous communities. Data also enable better engagement between citizens, institutions, and governments to improve decision-making. Ethical use of open data has the capacity to improve transparency and decision-making by providing Indigenous nations and communities with a better understanding of their peoples, territories, and resources. It similarly can provide greater insight into third-party policies and programs affecting Indigenous Peoples. C3: For equitable outcomes Indigenous data are grounded in community values, which extend to society at large. Any value created from Indigenous data should benefit Indigenous communities in an equitable manner and contribute to Indigenous aspirations for wellbeing. Care Principles - Authority to Control Indigenous Peoples’ rights and interests in Indigenous data must be recognised and their authority to control such data be empowered. Indigenous data governance enables Indigenous Peoples and governing bodies to determine how Indigenous Peoples, as well as Indigenous lands, territories, resources, knowledges and geographical indicators, are represented and identified within data. A1 Recognizing rights and interests Indigenous Peoples have rights and interests in both Indigenous Knowledge and Indigenous data. Indigenous Peoples have collective and individual rights to free, prior, and informed consent in the collection and use of such data, including the development of data policies and protocols for collection. A2: Data for governance Indigenous Peoples have the right to data that are relevant to their world views and empower self-determination and effective self-governance. Indigenous data must be made available and accessible to Indigenous nations and communities in order to support Indigenous governance. A3: Governance of data Indigenous Peoples have the right to develop cultural governance protocols for Indigenous data and be active leaders in the stewardship of, and access to, Indigenous data especially in the context of Indigenous Knowledge. Care Principles - Responsibility Those working with Indigenous data have a responsibility to share how those data are used to support Indigenous Peoples’ selfdetermination and collective benefit. Accountability requires meaningful and openly available evidence of these efforts and the benefits accruing to Indigenous Peoples. R1: For positive relationships Indigenous data use is unviable unless linked to relationships built on respect, reciprocity, trust, and mutual understanding, as defined by the Indigenous Peoples to whom those data relate. Those working with Indigenous data are responsible for ensuring that the creation, interpretation, and use of those data uphold, or are respectful of, the dignity of Indigenous nations and communities. R2: For expanding capability and capacity Use of Indigenous data invokes a reciprocal responsibility to enhance data literacy within Indigenous communities and to support the development of an Indigenous data workforce and digital infrastructure to enable the crea","date":"0001-01-01","objectID":"/fundamentals/workspaces-vs-repositories/:0:0","tags":null,"title":"Workspaces vs Repositories","uri":"/fundamentals/workspaces-vs-repositories/"}]